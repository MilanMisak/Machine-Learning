\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[margin=0.8in]{geometry}
\begin{document}
{\bf Names:} Jack Bracewell, Milan Misak, Craig Ellis \\
{\bf Usernames:} jb2910, mm5510, ce710 \\
{\bf Group Number: 28}  \\ \\

\section*{Assignment 5: T-test}

\subsection*{Evaluation results}

\subsubsection*{Experimental results using clean and noisy data}
\begin{table}[h]
\centering
\begin{tabular}{l | r r r}
Emotion   & Trees   & Networks & CBR     \\
\hline
Anger     & 28.4644 & 24.4726  & 24.0602 \\
Disgust   & 33.7349 & 60.0536  & 53.5484 \\
Fear      & 16.2393 & 46.3950  & 42.6036 \\
Happiness & 73.4793 & 77.4775  & 72.4211 \\
Sadness   & 33.5484 & 39.4366  & 34.4371 \\
Surprise  & 53.0612 & 75.4808  & 77.0563 \\
\end{tabular}
\caption{F1 measures}
\end{table}

\subsubsection*{T-test results using clean and noisy data}
\begin{table}[h]
\centering
\begin{tabular}{l l | r r}
Emotion   &          & Clean Data & Noisy Data \\
\hline
Anger     & Tree/Net & 0          & 1          \\
          & Tree/CBR & 1          & 1          \\
          & Net/CBR  & 0          & 0          \\
Disgust   & Tree/Net & 0          & 0          \\
          & Tree/CBR & 0          & 0          \\
          & Net/CBR  & 0          & 0          \\
Fear      & Tree/Net & 1          & 1          \\
          & Tree/CBR & 1          & 0          \\
          & Net/CBR  & 0          & 0          \\
Happiness & Tree/Net & 0          & 1          \\
          & Tree/CBR & 0          & 0          \\
          & Net/CBR  & 0          & 1          \\
Sadness   & Tree/Net & 1          & 1          \\
          & Tree/CBR & 0          & 0          \\
          & Net/CBR  & 0          & 1          \\
Surprise  & Tree/Net & 1          & 0          \\
          & Tree/CBR & 1          & 0          \\
          & Net/CBR  & 0          & 0          \\
\end{tabular}
\caption{T-test results}
\end{table}

\subsubsection*{Which algorithm performed better overall in terms of values of $F_1$ measure (part I)? Which algorithm performed better when comparison was performed using the t-test (part II and part III)? Can we claim that this algorithm is a better learning algorithm than the others in general? Why? Why not?}

The neural networks algorithm performed best in terms of values of $F_1$ measure; they had the highest $F_1$ measures for every emotion with the exception of anger and surprise. \\ \\
Using the t-test, it is clear that the neural networks and the CBR give very similar results - the only statistically significant differences appear when classifying happiness and sadness with noisy data. Trees are significantly different more often, but the $F_1$ measures suggest that this is because the decision trees are usually worse than the other two. \\ \\
It is not possible to determine if there is a significant difference in performance unless the t-test proves the alternative hypothesis for both clean and noisy data. This never happens between the two best-performing algorithms (ANN and CBR), so we cannot say for sure whether one is better than the other.

\subsubsection*{How did you adjust the significance level in order to take into account the fact that you perform a multiple comparison test?}

We adjusted our chosen significance level (5\%) by dividing it by 3, where 3 is the number of comparisons needed for this multiple comparison test. This is the 'Bonferroni correction' example provided, and seemed sufficient for our purposes.

\subsubsection*{Which type of t-test did you use and why?}

We used the paired T-test, as the samples we were testing were not independent. Since the samples were drawn from the exact same data for each classification method, they are clearly all dependent.

\subsubsection*{Why do you think t-test was performed on the classification error and not the F1 measure? What's the theoretical justification for this decision?}

Classification error has higher variance which means it will be less likely that we will get a false TODO

\subsubsection*{What is the trade-off between the number of folds you use and the number of examples per fold? In other words, what is going to happen if you use more folds, so you will have fewer examples per fold, or if you use fewer folds, so you will have more examples per fold?}

Fewer folds obviously means that we will obtain fewer fold measurements, so it would be harder to tell if any of those measurements are anomalous. \\ \\
More folds means that more of the data set is used for training, and less for testing. This is likely to more accurately model how the fully-trained algorithm will perform, but since there are fewer test examples, it is harder to tell whether or not the results are anomalous.

\subsubsection*{Suppose that we want to add some new emotions to the existing dataset. Which of the examined algorithms are more suitable for incorporating the new classes in terms of engineering effort? Which algorithms need to undergo radical changes in order to include new classes?}

Case-based reasoning and decision trees are both quite easily extended by adding new classes of emotions. The algorithms can be just simply modified in a few places and they will still work very well.\\ \\
Neural networks, on the other hand, will need some additional effort to tweak performance after the algorithm is modified. Some optimisations will be needed for neural networks; for example figuring out the number of neurons in hidden layers, or the number of hidden layers, to make sure that they still classify examples as well as they possibly can.

\end{document}
